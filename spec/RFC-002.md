# RFC-002: Biological Entropy Engine

| Status | Draft |
| :--- | :--- |
| **Author** | HCP Architecture Team |
| **Created** | 2026-02-10 |
| **License** | CC0-1.0 |

## 1. Abstract
This RFC defines the **Biological Entropy Engine (BEE)**, a mechanism to capture the "creative fingerprint" of human authors. Unlike AI, which generates content linearly and probabilistically, humans exhibit non-linear patterns: hesitation, backtracking, and refactoring. We propose a lightweight client-side protocol to measure these "Cognitive Pauses" and hash them into a verifiable proof of human effort.

## 2. The Problem: Zero-Cost Content
AI models can generate infinite variations of code or prose at near-zero marginal cost. To value human creation, we need a "Proof of Work" analog for intellectual laborâ€”something easy for a human to produce (by simply working) but computationally expensive for an AI to simulate perfectly.

## 3. The Solution: "Proof of Hesitation"

### 3.1. Entropy Metrics
The BEE captures three primary signals:
1.  **Timing Variance (Flight Time)**: The micro-timing between keystrokes. Humans have distinct rhythmic signatures (e.g., faster on familiar trigrams, slower on complex logic).
2.  **Refactoring Entropy**: The ratio of *deleted/modified* characters to *final* characters. AI generation is typically additive (append-only); human creation is subtractive and iterative.
3.  **Hysteresis Loops**: The "time-to-commit" versus "code complexity" curve. A complex algorithm should correspond to higher cognitive pause times.

### 3.2. Privacy-Preserving Hashing
To protect user privacy (content and biometrics), raw keystroke data is **never** transmitted.
Instead, the client compiles a "Session Manifest":
$$ H_{session} = \text{Hash}( \text{TimeDelta}_{1} || \text{EditDistance}_{1} || ... || \text{TimeDelta}_{n} ) $$
This hash is then signed by the HCP-ID (RFC-001).

### 3.3. Asymmetric Work Function
For an AI to forge this proof, it must:
1.  Generate the final output (cheap).
2.  simulate the *entire evolutionary history* of that output, including realistic "mistakes," "backtracks," and human-like timing variations (expensive).
This forces the AI to run a "Human Simulator" significantly more complex than the generative model itself, reintroducing a cost function to spam.

## 4. Implementation Guidelines
- **IDE Plugins**: Lightweight background processes in VS Code / JetBrains / Obsidian.
- **Local Storage**: Entropy data is stored locally in an encrypted `.hcp/entropy` verification log.
- **Verification**: Verifiers check the signed hash against the claimed "Human Work Units" (HWU).

## 5. Future Work
- **Gaze Tracking**: Integration with eye-tracking hardware for higher-assurance environments.
- **Brain-Computer Interface (BCI)**: Direct neural entropy measurement (long-term roadmap).
